# MyPy configuration for WikiStream project
# Reference: https://mypy.readthedocs.io/en/stable/config_file.html

[mypy]
# Python version to check against
python_version = 3.11

# Warn when a function is called with argument of incompatible type
warn_redundant_casts = True

# Warn about unused ignores
warn_unused_ignores = True

# Warn about unused code
warn_unused_configs = True

# Warn when returning Any from function declared to return a more specific type
warn_return_any = True

# Strictness level
strict = False
check_untyped_defs = True
disallow_untyped_defs = False
disallow_incomplete_defs = False

# Error summary
show_error_context = True
show_column_numbers = True
show_error_codes = True
color_output = True

# Output format
pretty = True

# Ignore missing imports for external libraries
ignore_missing_imports = True

# Multiple jobs for faster checking
jobs = 4

# Per-module settings
[mypy-confluent_kafka.*]
ignore_missing_imports = True

[mypy-pyspark.*]
ignore_missing_imports = True

[mypy-pydeequ.*]
ignore_missing_imports = True

[mypy-sseclient.*]
ignore_missing_imports = True

[mypy-aws_msk_iam_sasl_signer.*]
ignore_missing_imports = True

[mypy-boto3.*]
ignore_missing_imports = True

[mypy-requests.*]
ignore_missing_imports = True

[mypy-botocore.*]
ignore_missing_imports = True

# Spark jobs often have patterns that don't fit strict typing
[mypy.spark.jobs.*]
disallow_untyped_defs = False
disallow_untyped_calls = False

# Producer module
[mypy.producer.*]
disallow_untyped_defs = False

# DQ module
[mypy.spark.jobs.dq.*]
disallow_untyped_defs = False

# Schemas module
[mypy.spark.schemas.*]
disallow_untyped_defs = False
